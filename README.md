# ğŸ™ï¸ Municipal Waste Management Cost Prediction

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Scikit Learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![Kaggle](https://img.shields.io/badge/Kaggle-Dataset-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/datasets/shashwatwork/municipal-waste-management-cost-prediction)

---

## ğŸ“‹ Project Overview

This project predicts **municipal solid waste (MSW) management costs** for Italian municipalities using machine learning and deep learning techniques. The study rigorously compares classical regression models against deep learning architectures within a **K-Fold Cross-Validation** framework.

> **Key Finding**: Simple linear models can outperform complex neural networks on structured tabular data! ğŸ¯

---

## ğŸ“Š Dataset

**Source**: [Kaggle - Municipal Waste Management Cost Prediction](https://www.kaggle.com/datasets/shashwatwork/municipal-waste-management-cost-prediction)

| **Attribute** | **Details** |
|---------------|-------------|
| ğŸ“ Municipalities | 4,341 Italian cities |
| ğŸ¯ Target Variable | `msw` (Municipal Solid Waste in kg) |
| ğŸ“ˆ Input Features | 18 features: population, area, altitude, urbanization index, waste composition |

### ğŸ—‚ï¸ Key Features

- **Demographic**: Population (`pop`), Area (`area`), Altitude (`alt`)
- **Urban Metrics**: Urbanization index (`urb`)
- **Waste Composition**: Organic, Paper, Plastic, Glass percentages

---

## ğŸ”¬ Methodology & Pipeline

### ğŸ› ï¸ Data Preprocessing
```
ğŸ“¥ Raw Data
   â†“
ğŸ”„ KNN Imputation (k=5) â†’ Handle missing values
   â†“
ğŸ“ RobustScaler â†’ Normalize features & target
   â†“
âœ… Ready for Training
```

| **Step** | **Method** | **Purpose** |
|----------|-----------|-------------|
| **Imputation** | KNN Imputer (k=5) | Preserve local data structures |
| **Normalization** | RobustScaler | Minimize outlier impact |
| **Validation** | 6-Fold CV | Ensure generalizability |

---

### ğŸ¤– Models Evaluated

<table>
  <tr>
    <td align="center">ğŸ“<br><b>Ridge Regression</b><br>L2 regularization</td>
    <td align="center">ğŸ”®<br><b>SVM</b><br>RBF kernel</td>
    <td align="center">ğŸ§ <br><b>MLP</b><br>2 hidden layers</td>
    <td align="center">ğŸ—ï¸<br><b>1D-CNN</b><br>VGG-inspired blocks</td>
  </tr>
</table>

#### Model Architectures

1. **Ridge Regression (LR)** ğŸ“  
   - Linear model with L2 regularization
   - Fast and interpretable

2. **Support Vector Regression (SVM)** ğŸ”®  
   - RBF kernel for non-linear relationships
   - Tested for complex pattern detection

3. **Multi-Layer Perceptron (MLP)** ğŸ§   
   - Dense neural network: 2 Ã— 32-unit hidden layers
   - Adam optimizer

4. **1D-CNN** ğŸ—ï¸  
   - VGG-style convolutional blocks
   - Batch Normalization + Max Pooling
   - Designed for feature pattern extraction

---

## ğŸ“ˆ Results & Discussion

### ğŸ† Model Performance Comparison

| Model | RÂ² Score | RMSE | Performance Notes |
|-------|----------|------|-------------------|
| **ğŸ¥‡ Ridge Regression (LR)** | **0.9999** | **110,292** | **Best Performance.** Extremely fast and accurate. |
| **ğŸ¥ˆ MLP** | 0.9974 | 589,080 | High accuracy but computationally expensive. |
| **ğŸ¥‰ SVM** | 0.6549 | 7,165,693 | Failed to capture underlying patterns. |

---

### âš ï¸ Note on CNN Model

The 1D-CNN architecture was **fully implemented** (4 convolutional blocks with VGG-style design) but **excluded from final evaluation**.

**Why?** ğŸ¤”
- **Computational Cost**: Training time was prohibitively high within 6-Fold CV
- **Diminishing Returns**: Ridge Regression achieved RÂ² â‰ˆ 0.9999 with fraction of resources
- **Conclusion**: For this tabular dataset with strong linear relationships, complex deep learning architectures were unnecessary

**Implementation Status**: âœ… Code available but commented out in final run

---

## ğŸ’¡ Key Takeaways

> ### ğŸ“ "Simpler is Often Better"
> 
> For structured tabular data with clear linear relationships:
> - âœ… Ridge Regression outperformed complex neural networks
> - âœ… Lower computational cost = Faster deployment
> - âœ… Better interpretability for stakeholders

### ğŸ”‘ Success Factors

1. **ğŸ“Š Data Quality**: RobustScaler + KNN Imputation stabilized linear models
2. **ğŸ¯ Feature Engineering**: Well-structured input features enabled simple models to excel
3. **âš–ï¸ Model Selection**: Matching model complexity to data structure is crucial

---

## ğŸš€ Installation & Usage

### ğŸ“¦ Install Dependencies
```bash
# Install required packages
pip install pandas numpy matplotlib seaborn scikit-learn tensorflow
```

**Required Libraries:**
- pandas, numpy (data manipulation)
- matplotlib, seaborn (visualization)  
- scikit-learn (machine learning models)
- tensorflow/keras (deep learning models)

### ğŸ“¥ Download the Dataset

1. Visit Kaggle: [Municipal Waste Management Dataset](https://www.kaggle.com/datasets/shashwatwork/municipal-waste-management-cost-prediction)
2. Download and extract `public_data_waste_fee.csv`

### âš™ï¸ Configuration

**Important**: Update the dataset path in your notebook!
```python
class config:
    dir_dataset = "/path/to/your/public_data_waste_fee.csv"  # ğŸ‘ˆ Update this
```

### â–¶ï¸ Run the Analysis
```bash
jupyter notebook main.ipynb
```

The notebook will automatically:
- ğŸ“‚ Load and preprocess data
- ğŸ”„ Execute 6-Fold Cross-Validation
- ğŸ“Š Train and evaluate models (SVM, Ridge, MLP)
- ğŸ“ˆ Display performance metrics
---

## ğŸ› ï¸ Technologies

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" />
  <img src="https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white" />
  <img src="https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Seaborn-3776AB?style=for-the-badge" />
</p>

### ğŸ“š Libraries Used

| Category | Tools |
|----------|-------|
| **Data Manipulation** | Pandas, NumPy |
| **Visualization** | Matplotlib, Seaborn |
| **Machine Learning** | Scikit-learn (SVM, Ridge, KFold, RobustScaler, KNN Imputer) |
| **Deep Learning** | TensorFlow/Keras (Sequential API for MLP and CNN) |

---

## ğŸ“ Project Structure
```
municipal-waste-prediction/
â”‚
â”œâ”€â”€ main.ipynb                 # Main analysis notebook
â”œâ”€â”€ public_data_waste_fee.csv  # Dataset (download separately)
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸ‘¤ Author

**Mustafa Er**

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Mustafa-Er)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mustafa-er-483983146/)
[![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/aski1140)

---

## ğŸ“„ License

This project is open source and available for educational purposes.

---

<p align="center">
  <i>â­ If you found this project helpful, please consider giving it a star!</i>
</p>
